{
 "metadata": {
  "name": "",
  "signature": "sha256:46fcfd0c8079812fa5dfb7909c5fc3ac3ef3923b24df22731690c47352cdfa3c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import os\n",
      "import glob\n",
      "import xmltodict\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.dates as dates\n",
      "import matplotlib.ticker as tick\n",
      "import seaborn as sns\n",
      "import scipy.stats as sp\n",
      "import statsmodels.api as sm\n",
      "import statsmodels.tsa.tsatools as tools\n",
      "from pandas.stats.api import ols\n",
      "from datetime import datetime\n",
      "from pylab import rcParams\n",
      "rcParams['figure.figsize'] = 15, 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def compilation(inputfile):\n",
      "    \"\"\"\n",
      "    This function reads multiple Solinst transducer files in a directory and generates a compiled Pandas dataframe.\n",
      "    \n",
      "    inputfile = complete file path to input files; use * for wildcard in file name\n",
      "        example -> 'E:\\\\Snake Valley Water\\\\Transducer Data\\\\Raw_data_archive\\\\all\\\\LEV\\\\*baro*' picks any file containing 'baro'\n",
      "    \n",
      "    packages required:\n",
      "        pandas as pd\n",
      "        glob\n",
      "        os\n",
      "        xmltodict\n",
      "    \"\"\"\n",
      "    \n",
      "    def getfilename(path):\n",
      "        # this function extracts the file name without file path or extension\n",
      "        return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n",
      "    \n",
      "    # create empty dictionary to hold dataframes\n",
      "    f={}\n",
      "\n",
      "    # generate list of relevant files\n",
      "    filelist = glob.glob(inputfile)\n",
      "\n",
      "    # iterate through list of relevant files\n",
      "    for infile in filelist:\n",
      "        # get the extension of the input file\n",
      "        filetype = os.path.splitext(infile)[1]\n",
      "        # run computations using lev files\n",
      "        if filetype=='.lev':\n",
      "            # open text file\n",
      "            with open(infile) as fd:\n",
      "                # find beginning of data\n",
      "                indices = fd.readlines().index('[Data]\\n')\n",
      "\n",
      "            # convert data to pandas dataframe starting at the indexed data line\n",
      "            f[getfilename(infile)] = pd.read_table(infile, parse_dates=True, sep='     ', index_col=0,\n",
      "                                           skiprows=indices+2, names=['DateTime','Level','Temperature'], skipfooter=1,engine='python')\n",
      "            # add extension-free file name to dataframe\n",
      "            f[getfilename(infile)]['name'] = getfilename(infile)\n",
      "            \n",
      "        # run computations using xle files\n",
      "        elif filetype=='.xle':\n",
      "            # open text file\n",
      "            with open(infile) as fd:\n",
      "                # parse xml\n",
      "                obj = xmltodict.parse(fd.read(),encoding=\"ISO-8859-1\")\n",
      "            # navigate through xml to the data\n",
      "            wellrawdata = obj['Body_xle']['Data']['Log']\n",
      "            # convert xml data to pandas dataframe\n",
      "            f[getfilename(infile)] = pd.DataFrame(wellrawdata)\n",
      "            # get header names and apply to the pandas dataframe\n",
      "            f[getfilename(infile)][obj['Body_xle']['Ch1_data_header']['Identification']] = f[getfilename(infile)]['ch1']\n",
      "            f[getfilename(infile)][obj['Body_xle']['Ch2_data_header']['Identification']] = f[getfilename(infile)]['ch2']\n",
      "  \n",
      "            # add extension-free file name to dataframe\n",
      "            f[getfilename(infile)]['name'] = getfilename(infile)\n",
      "            # combine Date and Time fields into one field\n",
      "            f[getfilename(infile)]['DateTime'] = pd.to_datetime(f[getfilename(infile)].apply(lambda x: x['Date'] + ' ' + x['Time'], 1))\n",
      "            f[getfilename(infile)] = f[getfilename(infile)].reset_index()\n",
      "            f[getfilename(infile)] = f[getfilename(infile)].set_index('DateTime')\n",
      "            f[getfilename(infile)] = f[getfilename(infile)].drop(['Date','Time','@id','ch1','ch2','index','ms'],axis=1)\n",
      "        # run computations using csv files\n",
      "\n",
      "        else:\n",
      "            pass\n",
      "    # concatonate all of the dataframes in dictionary f to one dataframe: g\n",
      "    g = pd.concat(f)\n",
      "    # remove multiindex and replace with index=Datetime\n",
      "    g = g.reset_index()\n",
      "    g = g.set_index(['DateTime'])\n",
      "    # drop old indexes\n",
      "    g = g.drop(['level_0'],axis=1)\n",
      "    # remove duplicates based on index then sort by index\n",
      "    g['ind']=g.index\n",
      "    g.drop_duplicates(subset='ind',inplace=True)\n",
      "    g.drop('ind',axis=1,inplace=True)\n",
      "    g = g.sort()\n",
      "    # ensure that the Level and Temperature data are in a float format\n",
      "    g['Level'] = g['Level'].convert_objects(convert_numeric=True)\n",
      "    g['Temperature'] = g['Temperature'].convert_objects(convert_numeric=True)\n",
      "    outfile = g\n",
      "    return outfile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def readxle(infile):\n",
      "    def getfilename(path):\n",
      "        # this function extracts the file name without file path or extension\n",
      "        return path.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0]\n",
      "\n",
      "    # open text file\n",
      "    with open(infile) as fd:\n",
      "        # parse xml\n",
      "        obj = xmltodict.parse(fd.read(),encoding=\"ISO-8859-1\")\n",
      "    # navigate through xml to the data\n",
      "    wellrawdata = obj['Body_xle']['Data']['Log']\n",
      "    # convert xml data to pandas dataframe\n",
      "    f = pd.DataFrame(wellrawdata)\n",
      "    # get header names and apply to the pandas dataframe\n",
      "    f[obj['Body_xle']['Ch1_data_header']['Identification']] = f['ch1']\n",
      "    f[obj['Body_xle']['Ch2_data_header']['Identification']] = f['ch2']\n",
      "\n",
      "    # add extension-free file name to dataframe\n",
      "    f['name'] = getfilename(infile)\n",
      "    # combine Date and Time fields into one field\n",
      "    f['DateTime'] = pd.to_datetime(f.apply(lambda x: x['Date'] + ' ' + x['Time'], 1))\n",
      "    f['LEVEL'] = f['LEVEL'].convert_objects(convert_numeric=True)\n",
      "    f = f.reset_index()\n",
      "    f = f.set_index('DateTime')\n",
      "    f = f.drop(['Date','Time','@id','ch1','ch2','index','ms'],axis=1)\n",
      "    return f"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "readxle()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Barometric Efficiency"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook outlines methods to calculate barometric efficiency from groundwater well data. Barometric efficiency is the ratio of changes in well water levels to changes in barometric pressure (Rasmussen and Crawford, 1997).\n",
      "$$ \n",
      "be = \\frac{\\Delta wl}{\\Delta bp}\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are several different methods that one can apply to determine barometric efficiency."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Clark's method is one way to calculate barometric efficiency.  <a href=http://pubs.usgs.gov/wri/wri034267/wri03_4267.pdf>Merritt (2004)</a> outlines how to perform this method very well. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# clark's method\n",
      "cumls, ymod, resid, lag_time, dwl, dbp = baro_eff(g,barologtype.get(btype),'wtr_abv',100)\n",
      "dwl\n",
      "dbp\n",
      "\n",
      "sumbp = []\n",
      "sumwl = []\n",
      "signbp = []\n",
      "signwl = []\n",
      "for i in range(len(dwl)):\n",
      "    sumbp.append(abs(dbp[i]))\n",
      "    if round(dbp[i],4)==0:\n",
      "        sumwl.append(0)\n",
      "    elif dbp[i]>0 and dwl[i]>0:\n",
      "        sumwl.append(abs(dwl[i]))\n",
      "        signwl.append(1)\n",
      "        signbp.append(1)\n",
      "    elif dbp[i]<0 and dwl[i]<0:\n",
      "        sumwl.append(abs(dwl[i]))\n",
      "        signwl.append(-1)\n",
      "        signbp.append(-1)\n",
      "    elif dbp[i]>0 and dwl[i]<0:\n",
      "        sumwl.append(-1*abs(dwl[i]))\n",
      "        signwl.append(-1)\n",
      "        signbp.append(1)\n",
      "    elif dbp[i]<0 and dwl[i]>0:\n",
      "        sumwl.append(-1*abs(dwl[i]))\n",
      "        signwl.append(1)\n",
      "        signbp.append(-1)\n",
      "\n",
      "        \n",
      "be = round(np.sum(sumwl)/np.sum(sumbp),3)\n",
      "print np.sum(sumwl)\n",
      "print np.sum(sumbp)\n",
      "print be\n",
      "print np.sum(signwl)\n",
      "print np.sum(signbp)\n",
      "\n",
      "(be-(np.sum(signbp)/len(dwl))*(np.sum(dwl)/np.sum(sumbp)))/(1-(np.sum(signbp)/len(dwl))*(np.sum(dbp)/np.sum(sumbp)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "References"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=http://onlinelibrary.wiley.com/doi/10.1111/j.1745-6584.1997.tb00111.x/abstract>Rasmussen, T.C., and Crawford, L.A., 1997, Identifying and removing barometric pressure effects in confined and unconfined aquifers: Ground Water, v. 35, n. 3, pp. 502-511. doi: 10.1111/j.1745-6584.1997.tb00111.x</a><br/>\n",
      "<a href=http://pubs.usgs.gov/wri/wri034267/wri03_4267.pdf>Merritt, M.L., 2004, Estimating hydraulic properties of the\n",
      "floridan aquifer system by analysis of earth-tide, ocean-tide, and barometric effects, Collier and Hendry Counties, Florida: U.S. Geological Survey Water-Resources Investigations Report 03-4267, 70 p.</a><br/>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}